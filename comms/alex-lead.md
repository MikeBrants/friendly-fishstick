# Alex Lead ‚Äî Communications

## 2026-01-25 10:00 UTC ‚Äî NOUVELLES T√ÇCHES PRIORITAIRES (URGENT)

### FROM: Casey (Orchestrator)
### TO: Alex (Lead Quant)
### STATUS: TODO ‚Äî REPRIORITISATION MAJEURE
### PRIORITY: üî¥üî¥üî¥ CRITIQUE

---

## ‚ö†Ô∏è CHANGEMENT DE PRIORIT√âS

**La variance reduction est D√âPRIORITIS√âE**. Les t√¢ches ci-dessous prennent la priorit√© imm√©diate.

---

## TASK 0: Audit WFE Period Effect üö® BLOQUANT

### Statut: BLOQUANT ‚Äî Aucune d√©cision PROD tant que non r√©solu

### Probl√®me Identifi√©

Le calcul actuel de WFE dans `crypto_backtest/optimization/walk_forward.py:120` est suspect:

```python
efficiency_ratio = _ratio(mean_oos_return, mean_is_return) * 100.0
```

**Issues potentielles:**
1. **Utilise les returns** au lieu des Sharpe ratios (WFE classique = OOS_Sharpe / IS_Sharpe)
2. **Multiplication par 100** ‚Üí Valeurs gonfl√©es (ex: WFE 2.36 pour ETH semble trop haut)
3. **Period effect**: Les fen√™tres IS (180d) vs OOS (30d) ont des r√©gimes diff√©rents

### Questions √† Auditer

1. **Le calcul WFE est-il correct?** Comparer avec la d√©finition standard (Robert Pardo)
2. **Y a-t-il un biais temporel?** Les IS contiennent-ils syst√©matiquement plus de bull markets?
3. **Les WFE > 2.0 sont-ils r√©alistes?** (ETH: 2.36, SHIB: 2.27) ‚Äî Normalement WFE < 1.0 est attendu

### R√©f√©rences

- **Robert Pardo** (2008) "The Evaluation and Optimization of Trading Strategies"
- **WFE Standard**: Efficiency = OOS_Performance / IS_Performance, attendu entre 0.5-0.8

### Deliverable

Cr√©er fichier: `reports/wfe-audit-2026-01-25.md`
- Diagnostic du calcul actuel
- Comparaison avec d√©finition standard
- Recommandation: FIX ou KEEP avec justification

---

## TASK 1: Impl√©menter PBO (Probability of Backtest Overfitting) üî¥ CRITIQUE

### Statut: CRITIQUE ‚Äî N√©cessaire pour validation statistique

### Contexte

Le DSR actuel (`deflated_sharpe.py`) corrige le trial count mais **n'est pas le vrai PBO**.

**PBO** (Bailey & L√≥pez de Prado, 2014) = Probabilit√© que la meilleure strat√©gie backtest soit overfitt√©e.

### D√©finition Formelle

```
PBO = Probability that OOS performance of "best" IS strategy ranks below median

M√©thodologie:
1. Diviser donn√©es en S sous-ensembles (ex: S=16)
2. Former toutes combinaisons C(S, S/2) de training sets
3. Pour chaque combo: identifier "best" strategy sur IS, mesurer rang OOS
4. PBO = proportion de combos o√π rang OOS < m√©diane
```

### Impl√©mentation Requise

**Fichier**: `crypto_backtest/validation/pbo.py`

```python
def probability_of_backtest_overfitting(
    returns_matrix: pd.DataFrame,  # N strategies x T periods
    n_splits: int = 16,
    risk_free: float = 0.0
) -> dict:
    """
    Calculate PBO using CSCV (Combinatorially Symmetric Cross-Validation).

    Returns:
        pbo: float [0,1] ‚Äî probability of overfitting
        logits: array ‚Äî distribution of relative ranks
        threshold: float ‚Äî PBO threshold for significance
    """
```

### Seuils

| PBO | Verdict |
|-----|---------|
| < 0.15 | ‚úÖ PASS ‚Äî Low overfitting risk |
| 0.15-0.30 | ‚ö†Ô∏è MARGINAL ‚Äî Proceed with caution |
| > 0.30 | ‚ùå FAIL ‚Äî High overfitting probability |

### R√©f√©rences Acad√©miques

1. **Bailey, D. H., & L√≥pez de Prado, M. (2014)**
   "The Probability of Backtest Overfitting"
   *Journal of Computational Finance*
   https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2326253

2. **Bailey, D. H., Borwein, J., L√≥pez de Prado, M., & Zhu, Q. J. (2014)**
   "Pseudo-Mathematics and Financial Charlatanism"
   *Notices of the AMS*

3. **L√≥pez de Prado, M. (2018)**
   "Advances in Financial Machine Learning" ‚Äî Chapter 11: Backtesting

### Code de R√©f√©rence (MLFinLab)

```python
# Reference: hudson-and-thames/mlfinlab
# Module: mlfinlab.cross_validation.combinatorial

from itertools import combinations
import numpy as np
from scipy.special import comb

def cscv_pbo(strategy_returns, n_groups=16):
    """
    Combinatorially Symmetric Cross-Validation for PBO.

    1. Split time series into n_groups blocks
    2. Enumerate all C(n_groups, n_groups/2) train/test splits
    3. For each split:
       - Rank strategies by IS Sharpe
       - Record OOS rank of "best" IS strategy
    4. PBO = P(OOS_rank <= median)
    """
    n_combos = int(comb(n_groups, n_groups // 2))
    oos_ranks = []

    for train_idx in combinations(range(n_groups), n_groups // 2):
        test_idx = [i for i in range(n_groups) if i not in train_idx]

        # Calculate IS performance
        is_sharpes = calculate_sharpes(strategy_returns, train_idx)
        best_is_strategy = np.argmax(is_sharpes)

        # Calculate OOS rank of best IS strategy
        oos_sharpes = calculate_sharpes(strategy_returns, test_idx)
        oos_rank = rankdata(-oos_sharpes)[best_is_strategy]

        # Relative rank (0 = best, 1 = worst)
        relative_rank = oos_rank / len(oos_sharpes)
        oos_ranks.append(relative_rank)

    # PBO = proportion where OOS rank is below median
    pbo = np.mean(np.array(oos_ranks) > 0.5)
    return pbo, oos_ranks
```

---

## TASK 2: Impl√©menter CPCV (Combinatorial Purged Cross-Validation)

### Statut: HIGH ‚Äî Compl√®te PBO pour validation robuste

### Contexte

CPCV est la m√©thode de cross-validation recommand√©e par L√≥pez de Prado pour les s√©ries financi√®res.

**Probl√®me des CV classiques**: Data leakage temporel (information future dans training set)

**Solution CPCV**:
1. **Purging**: Supprimer observations autour du split (√©vite leakage)
2. **Embargo**: Gap temporel entre train/test
3. **Combinatorial**: Toutes les combinaisons possibles de folds

### Impl√©mentation Requise

**Fichier**: `crypto_backtest/validation/cpcv.py`

```python
from typing import Generator, Tuple
import numpy as np
import pandas as pd
from itertools import combinations

class CombinatorialPurgedKFold:
    """
    Combinatorial Purged K-Fold Cross-Validation.

    Implements L√≥pez de Prado's CPCV methodology:
    - Purging: Remove observations within embargo period of test set
    - Embargo: Additional gap after test set before training resumes
    - Combinatorial: Generate all C(n_splits, n_test_splits) combinations
    """

    def __init__(
        self,
        n_splits: int = 6,
        n_test_splits: int = 2,
        purge_gap: int = 0,
        embargo_pct: float = 0.01
    ):
        self.n_splits = n_splits
        self.n_test_splits = n_test_splits
        self.purge_gap = purge_gap
        self.embargo_pct = embargo_pct

    def split(
        self,
        X: pd.DataFrame,
        y: pd.Series = None,
        groups: pd.Series = None
    ) -> Generator[Tuple[np.ndarray, np.ndarray], None, None]:
        """
        Generate train/test indices with purging and embargo.

        Yields:
            train_indices, test_indices for each combination
        """
        pass  # Implement

    def get_n_splits(self) -> int:
        """Return number of splitting iterations."""
        from scipy.special import comb
        return int(comb(self.n_splits, self.n_test_splits))
```

### R√©f√©rences

1. **L√≥pez de Prado, M. (2018)**
   "Advances in Financial Machine Learning" ‚Äî Chapter 7: Cross-Validation in Finance

2. **MLFinLab Documentation**
   https://mlfinlab.readthedocs.io/en/latest/implementations/cross_validation.html

3. **Hudson & Thames Implementation**
   https://github.com/hudson-and-thames/mlfinlab/blob/master/mlfinlab/cross_validation/combinatorial.py

---

## üìö R√©f√©rences Obligatoires

### Papers L√≥pez de Prado (√Ä LIRE)

| Paper | Ann√©e | Relevance |
|-------|-------|-----------|
| "The Probability of Backtest Overfitting" | 2014 | TASK 1 ‚Äî PBO |
| "The Deflated Sharpe Ratio" | 2014 | Context DSR |
| "Pseudo-Mathematics and Financial Charlatanism" | 2014 | Pourquoi PBO |
| "Advances in Financial Machine Learning" Ch.7,11 | 2018 | CPCV, Backtesting |

### Repos GitHub √† Analyser

| Repo | Focus | URL |
|------|-------|-----|
| **mlfinlab** (Hudson & Thames) | PBO, CPCV, DSR | https://github.com/hudson-and-thames/mlfinlab |
| **vectorbt** | WFE, Optimization | https://github.com/polakowo/vectorbt |
| **backtesting.py** | Walk-Forward | https://github.com/kernc/backtesting.py |
| **freqtrade** | Hyperopt, Validation | https://github.com/freqtrade/freqtrade |
| **quantstats** | Metrics, Tearsheets | https://github.com/ranaroussi/quantstats |
| **riskfolio-lib** | Portfolio Optimization | https://github.com/dcajasn/Riskfolio-Lib |

### Focus Analyse GitHub

Pour chaque repo, documenter:
1. **Impl√©mentation PBO** ‚Äî Existe? Comment?
2. **Impl√©mentation CPCV** ‚Äî Existe? Param√®tres?
3. **Calcul WFE** ‚Äî D√©finition utilis√©e?
4. **Anti-overfitting** ‚Äî Autres techniques?

---

## üìä Priorit√©s Mises √† Jour

| # | Task | Priority | Status | Blocking |
|---|------|----------|--------|----------|
| 0 | WFE Period Effect Audit | üî¥üî¥üî¥ BLOQUANT | TODO | Oui |
| 1 | PBO Implementation | üî¥üî¥ CRITIQUE | TODO | Non |
| 2 | CPCV Implementation | üî¥ HIGH | TODO | Non |
| 3 | ~~Variance Reduction~~ | ‚¨ú D√âPRIORITIS√â | HOLD | Non |
| 4 | GitHub Repos Analysis | üü° MEDIUM | TODO | Non |

---

## Deliverables Attendus

1. **`reports/wfe-audit-2026-01-25.md`** ‚Äî Audit WFE (TASK 0)
2. **`crypto_backtest/validation/pbo.py`** ‚Äî PBO module (TASK 1)
3. **`crypto_backtest/validation/cpcv.py`** ‚Äî CPCV module (TASK 2)
4. **`reports/github-repos-analysis.md`** ‚Äî Analyse repos (TASK 4)

---

## Format de R√©ponse

```
HHMM INPROGRESS alex-lead -> casey-quant: TASK [N] en cours
Fichier: [path]
Progress: [X/Y steps]
Blockers: [if any]
```

Puis:
```
HHMM DONE alex-lead -> casey-quant: TASK [N] termin√©
Deliverable: [path to file]
Key Findings: [bullet points]
Recommendation: [action]
```

---

## ‚ö° Action Imm√©diate Requise

**Alex**: Commence par TASK 0 (WFE Audit) ‚Äî c'est BLOQUANT.

Les d√©cisions PROD sur les 11 assets valid√©s sont en suspens jusqu'√† confirmation que le calcul WFE est correct.

---
---

## ARCHIVE ‚Äî T√¢ches Pr√©c√©dentes

---

## 2026-01-24 22:30 UTC ‚Äî TASK: Variance Reduction Research

### FROM: Casey (Orchestrator)
### TO: Alex (Lead Quant)
### STATUS: TODO
### PRIORITY: üî¥ HIGH

---

## Contexte

Avec le nouveau seuil sensitivity √† 15%, plusieurs assets passent maintenant guard002.
Cependant, on veut **r√©duire la variance** m√™me en dessous de 15%, surtout pour les gros assets comme ETH.

**ETH baseline actuel**:
- Sensitivity: 12.96%
- Sharpe: 3.87
- WFE: 2.36

**Objectif**: Trouver des solutions pour r√©duire la variance sous 10% si possible, sans sacrifier le Sharpe.

---

## T√¢ches Assign√©es

### 1. Impl√©menter Deflated Sharpe Ratio (DSR) ‚Äî PRIORIT√â 1

Le DSR corrige directement pour le **trial count paradox** que tu as identifi√©.

**Fichier √† cr√©er**: `crypto_backtest/validation/deflated_sharpe.py`

**Formule**:
```
SR‚ÇÄ = œÉ(SR) √ó [(1-Œ≥)Œ¶‚Åª¬π(1-1/N) + Œ≥Œ¶‚Åª¬π(1-1/Ne)]
DSR = Œ¶((SR - SR‚ÇÄ) / œÉ(SR))
```

**Seuils recommand√©s**:
| DSR | Verdict |
|-----|---------|
| > 95% | PASS |
| 85-95% | MARGINAL |
| < 85% | FAIL |

**Int√©gration**: Ajouter comme `guard008` ou metric informative.

### 2. Rechercher Solutions Variance Reduction ‚Äî PRIORIT√â 2

**Assets cibles**: ETH (12.96%), CAKE (10.76%), autres >10%

**Pistes √† explorer**:
1. **Regime-aware WF splits** ‚Äî Les splits actuels ignorent si on coupe en bull/bear/sideways
2. **Parameter averaging** ‚Äî Moyenner top N trials au lieu de prendre le best
3. **Regularization Optuna** ‚Äî Ajouter p√©nalit√© variance dans objective
4. **Ensemble de param√®tres** ‚Äî Combiner plusieurs sets de params
5. **Reduced trial count** ‚Äî Tu as montr√© que 50 trials > 100 trials pour WFE

### 3. Recherche GitHub Quant Repos ‚Äî PRIORIT√â 3

**Objectif**: Trouver des strat√©gies/filtres compl√©mentaires sur les repos quant populaires.

**Repos √† explorer**:
- `quantopian/zipline`
- `pmorissette/bt`
- `ranaroussi/quantstats`
- `polakowo/vectorbt`
- `kernc/backtesting.py`
- `freqtrade/freqtrade`

**Focus**:
- Filtres de volatilit√©
- M√©thodes de r√©duction overfitting
- Walk-forward robustes
- Ensemble methods

---

## Deliverables Attendus

1. **Code DSR** (`crypto_backtest/validation/deflated_sharpe.py`)
2. **Rapport variance reduction** (solutions test√©es, r√©sultats)
3. **Liste de filtres/strat√©gies** identifi√©s sur GitHub (√† int√©grer ou tester)

---

## Timeline

| Task | Dur√©e estim√©e |
|------|---------------|
| DSR implementation | 1-2h |
| Variance reduction research | 2-4h |
| GitHub repos scan | 1-2h |

---

## Notes Techniques

### DSR ‚Äî Code de r√©f√©rence

```python
import numpy as np
from scipy.stats import norm, skew, kurtosis

def deflated_sharpe_ratio(returns, sharpe_observed, n_trials, annualization=1):
    """
    Calculate DSR - probability that observed Sharpe is statistically significant.
    
    Args:
        returns: array of strategy returns (not annualized)
        sharpe_observed: observed Sharpe ratio (not annualized)
        n_trials: number of optimization trials tested
        annualization: 1 for already annualized
    
    Returns:
        dsr: probability [0,1] that Sharpe is significant
        sr0: threshold Sharpe expected from random trials
    """
    T = len(returns)
    sr = sharpe_observed / annualization
    
    # Higher moments
    gamma3 = skew(returns)
    gamma4 = kurtosis(returns, fisher=False)
    
    # Variance of Sharpe estimator
    var_sr = (1 + 0.5 * sr**2 - gamma3 * sr + ((gamma4 - 3) / 4) * sr**2) / (T - 1)
    std_sr = np.sqrt(var_sr)
    
    # Euler-Mascheroni constant
    gamma = 0.5772156649
    
    # SR0: threshold expected by chance
    sr0 = std_sr * ((1 - gamma) * norm.ppf(1 - 1/n_trials) + 
                     gamma * norm.ppf(1 - 1/(n_trials * np.e)))
    
    # DSR
    dsr = norm.cdf((sr - sr0) / std_sr)
    
    return dsr, sr0
```

### Regime-Aware Splits

Probl√®me actuel: Les splits WF (60/20/20) ignorent la distribution des r√©gimes.
- Si IS = 100% BULL et OOS = 100% BEAR ‚Üí WFE biais√©
- Solution: Stratified splits par r√©gime

---

## R√©ponse Attendue

Format:
```
HHMM INPROGRESS alex-lead -> casey-quant: [Task] en cours
Fichier: [path]
Progress: [X/Y steps]
ETA: [time]
```

Puis:
```
HHMM DONE alex-lead -> casey-quant: [Task] termin√©
Deliverable: [path to file/report]
Summary: [key findings]
Next: [recommended actions]
```
