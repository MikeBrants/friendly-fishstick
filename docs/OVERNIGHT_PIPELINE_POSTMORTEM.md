# Overnight Pipeline Post-Mortem

**Date:** 2026-01-24  
**Pipeline:** run_overnight_reset.ps1  
**Issue:** Doublons en Phase 2 (chaque asset valid√© 2√ó)

---

## üîç Analyse du Probl√®me

### **Cause Root:**

Le script `run_full_pipeline.py` g√©n√®re **2 fichiers CSV identiques** par run:

```
outputs/
‚îú‚îÄ‚îÄ phase1_reset_batch1_prod_multiasset_scan_20260124_034427.csv     (4598 bytes)
‚îî‚îÄ‚îÄ phase1_reset_batch1_prod_multi_asset_scan_20260124_034427.csv   (4598 bytes)
                                        ^^^^ underscore ajout√©
```

Ces deux fichiers contiennent **exactement les m√™mes donn√©es** (confirm√©: taille identique, contenu identique).

### **Propagation du Bug:**

Le script PowerShell `run_overnight_reset.ps1` (ligne 167) lit **tous** les fichiers:

```powershell
$scan_files = Get-ChildItem -Path "outputs" -Filter "*phase1_reset*.csv" | 
    Where-Object { $_.LastWriteTime -gt (Get-Date).AddHours(-4) }
```

**Sans d√©duplication** (ligne 173-180):

```powershell
$success_assets = @()
foreach ($file in $scan_files) {
    foreach ($line in $content) {
        if ($line -match "^([A-Z]+),SUCCESS") {
            $success_assets += $matches[1]  # ‚ùå Pas de d√©doublonnage
        }
    }
}
```

**R√©sultat:**
- 7 assets SUCCESS dans Batch 1 ‚Üí lus dans 2 fichiers ‚Üí **14 entr√©es** dans `$success_assets`
- Phase 2 valide ces 14 entr√©es ‚Üí chaque asset valid√© **2 fois** (Run 1 + Run 2 √ó 2)

---

## üìä Impact

### **Positif (Inattendu):**

‚úÖ **Donn√©es de reproducibilit√© enrichies:**
- Au lieu de 2 runs (Run 1 + Run 2), nous avons **4 runs** par asset
- **Confiance statistique accrue** sur la stabilit√© des param√®tres
- Peut d√©tecter des variations subtiles (si Run 1a ‚â† Run 1b)

‚úÖ **D√©tection pr√©coce de non-d√©terminisme:**
- Si les 2 premi√®res ex√©cutions donnent des r√©sultats diff√©rents ‚Üí bug imm√©diat

### **N√©gatif:**

‚ùå **Temps d'ex√©cution doubl√©:**
- Phase 2 attendue: ~3h (15 assets √ó 2 runs √ó 6 min)
- Phase 2 r√©elle: **~6h** (30 validations au lieu de 15)
- Pipeline total: 12h30 au lieu de 6h

‚ùå **Ressources CPU gaspill√©es:**
- 2√ó plus de trials Optuna (~600 trials par asset au lieu de 300)
- Co√ªt cloud/√©lectricit√© (si applicable)

‚ùå **Log pollu√©:**
- Doublons dans les SUCCESS (voir ligne 104-140 du log: ETH, JOE, ANKR, etc. √ó 2)
- Difficile de distinguer les runs l√©gitimes

---

## ‚úÖ Solutions Impl√©ment√©es

### **1. Script Corrig√©: `run_overnight_reset_fixed.ps1`**

**Changements:**

1. **Filtrage des fichiers** (ligne 165):
```powershell
# AVANT
$scan_files = Get-ChildItem -Path "outputs" -Filter "*phase1_reset*.csv"

# APR√àS
$scan_files = Get-ChildItem -Path "outputs" -Filter "*phase1_reset*multiasset_scan*.csv" | 
    Where-Object { $_.Name -notmatch "multi_asset_scan" }
```

2. **D√©duplication explicite** (ligne 186):
```powershell
# Ajout√© apr√®s la boucle de parsing
$success_assets = $success_assets | Select-Object -Unique
```

### **2. Fix Permanent dans `run_full_pipeline.py`**

**Recommandation:** Modifier le script Python pour ne g√©n√©rer qu'**un seul fichier CSV**.

**Localisation du bug:** `crypto_backtest/optimization/parallel_optimizer.py`, ligne ~1180:

```python
# Probablement quelque chose comme:
output_file_1 = f"multiasset_scan_{timestamp}.csv"
output_file_2 = f"multi_asset_scan_{timestamp}.csv"  # ‚ùå Doublon inutile
```

**Action:** Supprimer la g√©n√©ration du deuxi√®me fichier.

---

## üìà R√©sultats du Pipeline Overnight

### **Phase 1: Re-Screening (04:40 compl√©t√©)**

| Batch | Assets | SUCCESS | FAIL | Taux |
|:------|:-------|:--------|:-----|:-----|
| 1. Anciens PROD | 15 | 7 | 8 | 47% |
| 2. High Cap | 15 | 1 | 14 | 7% |
| 3. DeFi + L2 | 10 | 6 | 4 | 60% |
| 4. Gaming | 10 | 0 | 10 | 0% |
| 5. Infra | 10 | 1 | 9 | 10% |
| **TOTAL** | **60** | **15** | **45** | **25%** |

**Assets SUCCESS (d√©dupliqu√©s):**
- ETH, JOE, ANKR, DOGE, DOT, NEAR, SHIB (Batch 1)
- HBAR (Batch 2)
- CRV, SUSHI, RUNE, TIA, CAKE, TON (Batch 3)
- EGLD (Batch 5)

### **Phase 2: Validation (93% compl√©t√© √† 15:52)**

**Validations compl√©t√©es:** 14/15 assets
- 28 runs au lieu de 14 (doublons)
- TIA Run 2 en cours
- EGLD en attente

---

## üéØ Actions Recommand√©es

### **Imm√©diat:**

1. **Laisser finir le pipeline actuel** (~30 min restant)
   - TIA Run 2 + EGLD Run 1 + Run 2

2. **Analyser reproducibilit√©** avec les doublons:
   ```bash
   # Comparer les 4 runs pour chaque asset
   python scripts/compare_reproducibility_extended.py --phase2-results
   ```

3. **Validation guards (@Sam):**
   - V√©rifier 7/7 guards PASS pour les 15 assets
   - Confirmer reproducibilit√© sur les 4 runs (variance < 1%)

### **Futur:**

4. **Utiliser le script corrig√©:**
   ```powershell
   # Au lieu de:
   .\scripts\run_overnight_reset.ps1
   
   # Utiliser:
   .\scripts\run_overnight_reset_fixed.ps1
   ```

5. **Fix permanent dans Python:**
   - Investiguer `parallel_optimizer.py` pour √©liminer le doublon de fichier
   - PR + tests unitaires

6. **Monitoring am√©lior√©:**
   - Ajouter un check de d√©duplication dans le script PowerShell
   - Alerte si `$success_assets.Count ‚â† ($success_assets | Select-Object -Unique).Count`

---

## üìù Lessons Learned

1. **Toujours d√©dupliquer les listes** en shell scripting
2. **Un seul fichier output par run** (principe KISS)
3. **Les bugs peuvent avoir des side-effects positifs** (4 runs = meilleure confiance)
4. **Valider les assumptions** (pourquoi 2 fichiers CSV identiques ?)

---

## ‚úÖ Verdict

**Impact global:** Mineur ‚ö†Ô∏è
- Pipeline fonctionnel malgr√© le bug
- Temps doubl√© mais donn√©es enrichies
- Fix trivial pour les prochains runs

**Priorit√© fix:** **P2** (non-bloquant, mais √† corriger)

---

**Auteur:** Jordan (Agent Dev)  
**Reviewer:** Casey (Quant Lead)  
**Status:** DOCUMENT√â, FIX READY
