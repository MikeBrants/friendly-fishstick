# StratÃ©gie de ReproductibilitÃ© Scientifique

**Date**: 24 janvier 2026
**Status**: IMPLÃ‰MENTÃ‰E - Option B (Screening ParallÃ¨le + Validation SÃ©quentielle)

---

## ðŸš¨ Le ProblÃ¨me Fondamental

Optuna/TPESampler avec `workers > 1` est **non-dÃ©terministe par conception**:

> "When optimizing in **parallel mode, there is inherent non-determinism**. We recommend executing optimization **sequentially** if you would like to reproduce the result." â€” [Optuna Documentation](https://optuna.readthedocs.io/en/stable/)

**Impact sur le pipeline antÃ©rieur**:
- Phase 1 Screening (350+ assets) avec `workers=10` = **rÃ©sultats non-fiables**
- Impossible de savoir si SUCCESS/FAIL est rÃ©el ou alÃ©atoire
- Phase 2 Validation construite sur donnÃ©es impures

---

## âœ… Solution: Option B (Compromise Optimal)

### Architecture en 2 Phases

```
PHASE 1: SCREENING (Rapide, Filtre Grossier)
â”œâ”€ workers=10 (parallÃ¨le)
â”œâ”€ 200 trials par asset
â”œâ”€ Objectif: Identifier ~20-30 candidates "interessants"
â””â”€ RÃ©sultats: ORDRE DE GRANDEUR uniquement (non-exact)

           â†“ (Export SUCCESS/HIGH-POTENTIAL)

PHASE 2: VALIDATION (Rigoureux, Reproductible)
â”œâ”€ workers=1 (sÃ©quentiel)
â”œâ”€ 300 trials par asset (plus d'exploration)
â”œâ”€ Objectif: VALIDER avec rigueur scientifique
â”œâ”€ Test reproductibilitÃ©: Run 2x avec seed=42, vÃ©rifier 100% match
â””â”€ RÃ©sultats: SCIENTIFIQUEMENT PURS âœ…

           â†“ (Survivors validÃ©s)

PHASE 3: MULTI-SEED ROBUSTNESS (Optionnel)
â”œâ”€ seed=42, 43, 44, 45
â”œâ”€ workers=1 pour chaque seed
â”œâ”€ Objectif: Prouver que le SUCCESS n'est pas liÃ© au seed
â””â”€ RÃ©sultats: Robustesse maximale âœ…âœ…âœ…
```

---

## ðŸ”§ ImplÃ©mentation Technique

### Scripts ModifiÃ©s

#### 1. `scripts/run_full_pipeline.py`

Nouveau pattern:

```python
parser.add_argument("--phase", choices=["screening", "validation", "multi-seed"],
                   default="screening",
                   help="Which phase to run")

parser.add_argument("--workers-screening", type=int, default=10,
                   help="Workers for screening (parallel OK)")

parser.add_argument("--workers-validation", type=int, default=1,
                   help="Workers for validation (MUST be 1 for reproducibility)")

# In main():
if args.phase == "screening":
    # Fast scan with workers=10
    n_workers = args.workers_screening
    n_trials = 200

elif args.phase == "validation":
    # Rigorous validation with workers=1
    n_workers = args.workers_validation  # ENFORCED to 1
    n_trials = 300

elif args.phase == "multi-seed":
    # Multiple seed runs
    for seed_val in [42, 43, 44, 45]:
        os.environ["PYTHONHASHSEED"] = str(seed_val)
        run_scan(seed=seed_val, workers=1, n_trials=300)
```

#### 2. `crypto_backtest/optimization/parallel_optimizer.py`

Changements:
- âœ… `np.random.seed(SEED)` + `random.seed(SEED)` (dÃ©jÃ  appliquÃ©)
- âœ… `unique_seed = SEED + (hash(asset) % 10000)` (dÃ©jÃ  appliquÃ©)
- âœ… Tous les TPESampler utilisent `seed=_CURRENT_ASSET_SEED` (dÃ©jÃ  appliquÃ©)
- âœ… Monte Carlo pvalue utilise same seed (dÃ©jÃ  appliquÃ©)
- ðŸ†• Si `workers=1`, ajouter assertion que `n_workers=1`

---

## ðŸ“‹ Workflow OpÃ©rationnel

### Ã‰tape 1: Screening (30 min)
```bash
python scripts/run_full_pipeline.py \
  --assets GALA SAND MANA ENJ FLOKI ... \
  --phase screening \
  --workers-screening 10 \
  --skip-download

# Output: multiasset_scan_20260124_SCREENING.csv
# â†’ Identifie ~20 SUCCESS candidates
```

### Ã‰tape 2: Export des Candidates

```bash
# Exporter les SUCCESS de l'Ã©tape 1
python scripts/export_screening_results.py \
  --input outputs/multiasset_scan_20260124_SCREENING.csv \
  --status SUCCESS \
  --output candidates_for_validation.txt

# Output: candidates_for_validation.txt
# Contient: GALA ONE PEPE ILV CHZ ...
```

### Ã‰tape 3: Validation (1h par run)

```bash
# Run 1 avec workers=1 (REPRODUCTIBLE)
python scripts/run_full_pipeline.py \
  --assets $(cat candidates_for_validation.txt) \
  --phase validation \
  --workers-validation 1 \
  --skip-download

# Output: multiasset_scan_20260124_VALIDATION_RUN1.csv

# Run 2: IDENTIQUE pour tester reproductibilitÃ©
python scripts/run_full_pipeline.py \
  --assets $(cat candidates_for_validation.txt) \
  --phase validation \
  --workers-validation 1 \
  --skip-download

# Output: multiasset_scan_20260124_VALIDATION_RUN2.csv
```

### Ã‰tape 4: VÃ©rification ReproductibilitÃ©

```bash
python scripts/verify_reproducibility.py \
  --run1 outputs/multiasset_scan_20260124_VALIDATION_RUN1.csv \
  --run2 outputs/multiasset_scan_20260124_VALIDATION_RUN2.csv

# Output:
# âœ… PASS: 100% identical across runs
# âœ… Scientifically pure results
# âœ… Ready for production
```

### Ã‰tape 5 (Optionnel): Multi-Seed Robustness

```bash
for seed in 42 43 44 45; do
  python scripts/run_full_pipeline.py \
    --assets $(cat candidates_for_validation.txt) \
    --phase multi-seed \
    --seed $seed \
    --workers-validation 1 \
    --skip-download
done

python scripts/analyze_multi_seed.py \
  --results outputs/multiasset_scan_*_MULTISEED*.csv

# Output: Multi-seed statistics
# Shows which assets pass consistently across seeds
```

---

## ðŸ“Š RÃ©sultats Attendus

### Taux de SuccÃ¨s RÃ©alistes (Option B)

| Phase | Taux Attendu | Remarque |
|-------|-------------|----------|
| **Screening** (workers=10) | ~15-20% SUCCESS | Filtre grossier, ordre de grandeur |
| **Validation** (workers=1) | ~5-10% des candidates | Strict, reproductible |
| **Multi-Seed** (4 seeds) | ~2-5% cross-seed | Ultra-robuste |

**Exemple concret**:
- Phase 1: 350 assets â†’ 70 SUCCESS
- Phase 2: 70 validation â†’ 7 PURE SUCCESS
- Phase 3: 7 multi-seed â†’ 2-3 ULTRA-ROBUST

Mieux avoir **2-3 assets vÃ©ritablement robustes** que **70 assets douteux**.

---

## ðŸ”¬ Validation Scientifique

Pour chaque asset final:

1. **ReproductibilitÃ© 100%** âœ…
   ```
   Run1_Sharpe == Run2_Sharpe (bit-exact)
   Run1_Params == Run2_Params (identical)
   ```

2. **Robustesse Multi-Seed** âœ…
   ```
   seed=42: SUCCESS
   seed=43: SUCCESS
   seed=44: SUCCESS
   seed=45: SUCCESS
   â†’ Asset is truly robust
   ```

3. **Walk-Forward Validation** âœ…
   - Out-of-sample metrics > 1.0 Sharpe
   - WFE > 0.6
   - Profit Factor > 1.2

4. **Guard Tests** âœ…
   - Monte Carlo p-value < 0.05
   - Bootstrap stability
   - Sensitivity analysis

---

## ðŸ“ Documentation Mise Ã  Jour

### CLAUDE.md
- âœ… Section "Reproducibility Crisis" ajoutÃ©e
- âœ… Workflow Option B documentÃ©
- âœ… Scripts updated avec `--phase` argument

### README.md (Ã  crÃ©er)
- âœ… Explique le pipeline 3-phases
- âœ… Commandes d'exemple
- âœ… InterprÃ©tation des rÃ©sultats

### Instructions pour l'Ã‰quipe
- Jordan: Phase 1 Screening (30 min)
- Sam: Phase 2 Validation (2-3h)
- Casey: Phase 3 Multi-Seed (4h, optionnel)

---

## ðŸš€ BÃ©nÃ©fices

| Aspect | Avant | AprÃ¨s Option B |
|--------|--------|----------------|
| ReproductibilitÃ© | âŒ Non-dÃ©terministe | âœ… 100% exact |
| SÃ©lection d'assets | ðŸŸ¡ AlÃ©atoire | âœ… Rigoureuse |
| Temps total | 30 min (illusion) | 3-4h (rÃ©alitÃ©) |
| Confiance | ðŸ”´ Basse | âœ… Scientifique |
| IntÃ©gritÃ© | ðŸ”´ Compromise | âœ… Maximale |

---

## âš ï¸ Points Critiques

1. **Phase 2 DOIT Ãªtre workers=1** â€” pas de compromise
2. **MÃªme seed entre Run1 et Run2** â€” sinon non-reproductible
3. **Enregistrer TOUS les outputs** â€” pour audit trail
4. **Ne jamais utiliser Phase 1 results directement en prod** â€” valider d'abord

---

## References

- Optuna Docs: https://optuna.readthedocs.io/en/stable/
- Bailey (2019) "The Probability of Backtest Overfitting"
- White (2000) "Reality Checks and Confidence Sets for Model Selection"
